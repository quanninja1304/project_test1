{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'grade_func' already exists and is not an empty directory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already up to date.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/hung20gg/grade_func.git\n",
    "!cd grade_func && git pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from grade_func.grader import test_func_from_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ex1: Write a function, using regex to validate the datetime format (1.5 point)\n",
    "Given a datetime as a string, check does the datetime satisfy the condition DD-MM-YYYY or DD/MM/YYYY. Return True or False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "patterns=[]\n",
    "def validate_datetime(date : str) -> bool:\n",
    "    #DD/MM/YYYY\n",
    "    patterns.append(r'(0[1-9]|[12][0-9]|3[01])[\\/-](0[13578]|1[02])[\\/-][1-9](\\d{3})$')\n",
    "    patterns.append(r'(0[1-9]|[12][0-9]|30)[\\/-](0[469]|11)[\\/-][1-9](\\d{3})$')\n",
    "    patterns.append(r'(29)[\\/-](02)[\\/-]\\d{2}(0[48]|[13579][26]|[2468][048])')\n",
    "    patterns.append(r'(0[1-9]|1[0-9]|2[0-8])[\\/-](02)[\\/-][1-9](\\d{3})$')\n",
    "\n",
    "    for pattern in patterns:\n",
    "        if re.match(pattern,date):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "validate_datetime(\"07/07/1927\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tests: 19\n",
      "Passed tests: 19\n",
      "Point for Question 1 is 1.5\n"
     ]
    }
   ],
   "source": [
    "q1 = test_func_from_file(validate_datetime,'hw9_q_1.txt',plain_text_input=True, max_grade=1.5)\n",
    "print(\"Point for Question 1 is\", q1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ex2: Sum of all element (1.5 point)\n",
    "Find the sum of all numerical element passed into the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_(*nums) -> int:\n",
    "    return sum(x for x in nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tests: 19\n",
      "Passed tests: 19\n",
      "Point for Question 2 is 1.5\n"
     ]
    }
   ],
   "source": [
    "q2 = test_func_from_file(sum_,'hw9_q_2.txt', max_grade=1.5)\n",
    "print(\"Point for Question 2 is\", q2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ex3: Dynamic function with **kwargs (2 point)\n",
    "\n",
    "You are given 2 function:\n",
    "\n",
    "$f(x_1, x_2, x_3, x_4) = x_1 + x_2^2 + x_3^2 + x_4$\n",
    "\n",
    "$g(x_1, x_2) = x_1 + x_2$\n",
    "\n",
    "\n",
    "You must write function f and g to satisfy the router below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22481438118"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f(x1,x2,x3,x4):\n",
    "    return x1+x2**2+x3**2+x4\n",
    "\n",
    "def g(x1,x2):\n",
    "    return x1+x2\n",
    "\n",
    "# Evaluate func\n",
    "def router(pick, x1, x2, x3, x4):\n",
    "    def your_func(pick, **kwargs):\n",
    "        if pick == 'f':\n",
    "            return f(x1,x2,x3,x4)\n",
    "        elif pick == 'g':\n",
    "            return g(x1,x2)\n",
    "    return your_func(pick, x1=x1, x2=x2, x3=x3, x4=x4)\n",
    "\n",
    "router('f', 170809, -10776, 149550, -57367)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tests: 19\n",
      "Passed tests: 19\n",
      "Point for Question 3 is 2.0\n"
     ]
    }
   ],
   "source": [
    "q3 = test_func_from_file(router, 'hw9_q_3.txt', max_grade=2)\n",
    "print(\"Point for Question 3 is\", q3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ex4: Vectorize a sentence with Word2Vec (5 point)\n",
    "\n",
    "For simplicity, we will ignore how Word2Vec was trained.\n",
    "\n",
    "Word2Vec is a hashmap (dictionary) with keys are the words and values are the corresponding vectors (50-dim) to the word. To encode a sentence to a vector, you simply get the mean vector of words in the sentence.\n",
    "\n",
    "Eg.\n",
    "```\n",
    "model = {\n",
    "    \"I\": [0,1,2],\n",
    "    \"love\":[1.5,2,0.3],\n",
    "    \"you\":[0.5,1,2]\n",
    "}\n",
    "```\n",
    "The encoding for sentence *I love you* is the mean value of `model[\"I\"]`, `model[\"love\"]`, \"model[\"you\"]`\n",
    "```\n",
    "vector = [2/3, 4/3, 4.3/3] \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in c:\\users\\laptop\\anaconda3\\lib\\site-packages (4.3.3)\n",
      "Requirement already satisfied: numpy<2.0,>=1.18.5 in c:\\users\\laptop\\anaconda3\\lib\\site-packages (from gensim) (1.26.4)\n",
      "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in c:\\users\\laptop\\anaconda3\\lib\\site-packages (from gensim) (1.13.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\laptop\\anaconda3\\lib\\site-packages (from gensim) (5.2.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~harset-normalizer (C:\\Users\\LapTop\\anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~harset-normalizer (C:\\Users\\LapTop\\anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~harset-normalizer (C:\\Users\\LapTop\\anaconda3\\Lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "# Load the pre-trained Word2Vec model\n",
    "model = api.load('glove-wiki-gigaword-50') # Here is your word2vec database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encode a sentence (2 point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00701397,  0.54196334, -0.19225435, -0.5246567 ,  0.7782766 ,\n",
       "       -0.04985666, -0.31802335,  0.1746592 , -0.52432996,  0.4764192 ,\n",
       "       -0.33454332,  0.93489003, -0.61863667, -0.164186  ,  1.1000067 ,\n",
       "        0.33991334,  0.29203   ,  0.35769334,  0.07931166, -0.724163  ,\n",
       "       -0.42256665,  0.87211996,  0.7086167 ,  0.45412335,  1.2277    ,\n",
       "       -2.0613    , -1.3180667 ,  0.23561667,  1.2105001 , -1.2606801 ,\n",
       "        3.3339665 ,  0.7460467 , -0.60946995,  0.23688667, -0.31138667,\n",
       "       -0.179042  ,  0.17087667,  0.119286  ,  0.3511467 , -0.56632334,\n",
       "        0.09226224, -0.03197267, -0.20612   ,  0.41710332,  0.168862  ,\n",
       "        0.18619333,  0.08125467, -0.8010633 , -0.20057969,  0.78086996],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "def clean_text(text: str) -> str:\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    return ' '.join(text.split()).strip()\n",
    "\n",
    "def get_vector(sentence: str) -> np.ndarray:\n",
    "    cleaned_sentence = clean_text(sentence)\n",
    "    words = cleaned_sentence.split()\n",
    "    word_vectors = []\n",
    "    \n",
    "    for word in words:\n",
    "        if word in model.key_to_index:\n",
    "            word_vectors.append(model[word])\n",
    "    \n",
    "    if not word_vectors:\n",
    "        print(\"Warning: No words found in the model.\")\n",
    "        return np.zeros(model.vector_size)\n",
    "\n",
    "    sentence_vector = np.mean(word_vectors, axis=0)\n",
    "    \n",
    "    return sentence_vector\n",
    "\n",
    "\n",
    "sentence = \"i love you\"\n",
    "vector = get_vector(sentence)\n",
    "vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate similarity of 2 sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity: 1.0000001192092896\n"
     ]
    }
   ],
   "source": [
    "def cosine_similarity(text1: str, text2: str) -> float:\n",
    "    \n",
    "    vector1 = get_vector(text1)\n",
    "    vector2 = get_vector(text2)\n",
    "    \n",
    "    if np.all(vector1 == 0) or np.all(vector2 == 0):\n",
    "        print(\"Warning: One or both vectors are zero vectors.\")\n",
    "        return 0.0\n",
    "    \n",
    "    cosine_sim = np.dot(vector1, vector2) / (np.linalg.norm(vector1) * np.linalg.norm(vector2))\n",
    "    \n",
    "    return cosine_sim\n",
    "\n",
    "sentence1 = \"I love you oppa\"\n",
    "sentence2 = \"I love you oppa\"\n",
    "similarity_score = cosine_similarity(sentence1, sentence2)\n",
    "print(f\"Cosine Similarity: {similarity_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get top-k similarity (2 point)\n",
    "\n",
    "Given a list of sentences (knowledge database) and a random sentence, return index of top-k similar sentence in the knowledge database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I live in the poor countryside with hundreds of hardships\\n',\n",
       " 'Wanting to move to the city, I have to strive so my stomach is always full\\n',\n",
       " 'Then I met you, the broken pieces linger, and at night I miss you\\n',\n",
       " 'In my dreams, I call your name, oh dear love\\n',\n",
       " 'Can you stay here?\\n',\n",
       " \"Do you know that outside, there's a storm?\\n\",\n",
       " 'There’s so much loneliness, oh dear love\\n',\n",
       " 'I just wish for you to have peace\\n',\n",
       " 'Holding hands tightly, pressing lips together\\n',\n",
       " 'Sitting on the hillside\\n',\n",
       " 'Who do you love, who are you cherishing?\\n',\n",
       " 'Or are you just alone?\\n',\n",
       " 'Waiting for the future\\n',\n",
       " 'Why not love right now?\\n',\n",
       " 'Give me your innocence\\n',\n",
       " 'Tonight, I will dream\\n',\n",
       " 'Lonely like a poet\\n',\n",
       " 'Sitting alone, lost in thought\\n',\n",
       " 'One person leaves, while the other stays\\n',\n",
       " 'Yet the heart remains confused\\n',\n",
       " 'The sky where we once shared sweet moments\\n',\n",
       " 'Gently holding hands\\n',\n",
       " 'Your dress lightly flutters\\n',\n",
       " 'Sitting on the hillside again\\n',\n",
       " 'You are like a drifting dream\\n',\n",
       " 'Quiet like the winter wind\\n',\n",
       " 'A cold night side by side\\n',\n",
       " 'Now, the weather makes your cheeks blush\\n',\n",
       " 'A life of peace, I feel at ease\\n',\n",
       " 'Yet fate blocks our love from becoming one']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"knowledge.txt\") as f:\n",
    "    database = f.readlines()\n",
    "database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_k_similar(text: str, k: int) -> list:\n",
    "    text = clean_text(text)\n",
    "    similarity = []\n",
    "    for index, line in enumerate(database):\n",
    "        line = line.strip()\n",
    "        similarity.append((index, cosine_similarity(line, text)))\n",
    "\n",
    "    similarity.sort(key=lambda x: x[1], reverse=True)\n",
    "    return [x[0] for x in similarity[:k]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[24, 11, 13, 10, 18, 5]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_k_similar(\"dolphins are gay sharks\",6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
